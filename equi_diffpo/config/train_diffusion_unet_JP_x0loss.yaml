defaults:
  - train_diffusion_unet
  - _self_
  - override task: mimicgen_abs_JP_x0loss

dataset: equi_diffpo.dataset.robomimic_replay_image_dataset_JP_x0loss.RobomimicReplayImageDataset_JP_x0loss
dataset_path: data/robomimic/datasets/${task_name}/${task_name}_abs_JP_x0loss.hdf5

policy:
  _target_: equi_diffpo.policy.diffusion_unet_hybrid_image_policy_x0loss.DiffusionUnetHybridImagePolicyX0loss


training:
  device: "cuda:0"
  seed: 0
  debug: False
  resume: True
  # optimization
  lr_scheduler: cosine
  lr_warmup_steps: 500
  num_epochs: ${eval:'50000 / ${n_demo}'}
  gradient_accumulate_every: 1
  # EMA destroys performance when used with BatchNorm
  # replace BatchNorm with GroupNorm.
  use_ema: True
  # training loop control
  # in epochs
  rollout_every: ${eval:'1000 / ${n_demo}'}
  checkpoint_every: ${eval:'1000 / ${n_demo}'}
  val_every: 1
  sample_every: 5
  # steps per epoch
  max_train_steps: null
  max_val_steps: null
  # misc
  tqdm_interval_sec: 1.0

